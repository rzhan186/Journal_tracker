# app.py

import streamlit as st
from tracking_main import (
    fetch_pubmed_articles_by_date,
    format_journal_abbreviation,
    fetch_preprints,
    load_pubmed_journal_abbreviations,
    format_boolean_keywords_for_pubmed,
    build_pubmed_query,
    generate_placeholder_csv,
    merge_and_highlight_articles,
    compile_keyword_filter,
    standardize_date_format,
    standardize_doi_format
    )

import pandas as pd
import os
import io
import logging
from store_subscription import store_user_subscription, generate_unsubscribe_token

from RateLimit import PubMedRateLimit

from datetime import datetime, timedelta
from dotenv import load_dotenv
from itsdangerous import URLSafeSerializer, URLSafeTimedSerializer, BadSignature

from email_dispatcher import send_email, generate_download_token, get_next_update_timeframe

load_dotenv()

# UPDATED: Use new domain-based email configuration
BREVO_API_KEY = st.secrets["BREVO_API_KEY"]
BREVO_SENDER_EMAIL = st.secrets["BREVO_SENDER_EMAIL"]
BREVO_SENDER_NAME = st.secrets["BREVO_SENDER_NAME"]

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

BASE_URL = "https://journaltracker.streamlit.app"

# Initialize rate limiter
if 'rate_limiter' not in st.session_state:
    st.session_state.rate_limiter = PubMedRateLimit()

rate_limiter = st.session_state.rate_limiter

# function to validate journal selection
def validate_and_format_journals(selected_journals):
    """
    Validate and format selected journals using the enhanced logic
    """
    journal_dict = load_pubmed_journal_abbreviations()
    formatted_journals = []
    
    for journal in selected_journals:
        try:
            formatted_journal = format_journal_abbreviation(journal, journal_dict)
            formatted_journals.append(formatted_journal)
        except ValueError as e:
            st.error(f"Journal validation error for '{journal}': {str(e)}")
            return None
    
    return formatted_journals

# Search Execution Function
def execute_subscription_search(journals, keywords, include_preprints, frequency):
    """Execute search based on subscription parameters"""
    # Calculate date range based on frequency
    today = datetime.today().date()
    
    if frequency == "weekly":
        days_back = 7
    elif frequency == "monthly":
        days_back = 30
    elif frequency.startswith("every"):
        # Extract number from "every X days"
        days_back = int(frequency.split()[1])
    else:
        days_back = 7  # Default fallback
    
    start_date = str(today - timedelta(days=days_back))
    end_date = str(today)
    
    all_articles = []
    
    try:
        # Search PubMed journals
        if journals:
            for journal in journals:
                articles = fetch_pubmed_articles_by_date(
                    journal, start_date, end_date, 
                    format_boolean_keywords_for_pubmed(keywords) if keywords else None
                )
                for article in articles:
                    article["Journal"] = journal
                    article["Source"] = "PubMed"
                all_articles.extend(articles)
        
        # Search preprints
        if include_preprints:
            for server in ["biorxiv", "medrxiv"]:
                preprints = fetch_preprints(
                    server=server,
                    start_date=start_date,
                    end_date=end_date,
                    keywords=keywords
                )
                for article in preprints:
                    article["Journal"] = server
                    article["Source"] = "Preprint"
                all_articles.extend(preprints)
        
        if all_articles:
            # Process results
            all_articles = standardize_date_format(all_articles)
            all_articles = standardize_doi_format(all_articles)
            merged = merge_and_highlight_articles(all_articles, [], keywords)
            return pd.DataFrame(merged)
        else:
            return pd.DataFrame()
            
    except Exception as e:
        logging.error(f"Error in subscription search: {e}")
        return pd.DataFrame()
    

# Streamlit app configuration
st.set_page_config(page_title="PubMed Journal Tracker", layout="centered")
st.title("ğŸ“š PubMed Journal Tracker")

# Check for unsubscribe token in the URL
if 'token' in st.query_params:
    token = st.query_params['token']
    action = st.query_params.get('action', 'unsubscribe')  # Default to unsubscribe
    
    if action == 'download':
        # Handle CSV download
        from app_csv_downloader import handle_download
        handle_download(token)
    else:
        # Handle unsubscribe
        from app_unsubscribe import handle_unsubscribe
        handle_unsubscribe(token)

else:
    # If no token is found, display the main application interface

    st.markdown("""
    Use this tool to search PubMed by journal, date range, and keywords.  
    You can also subscribe to automatic updates.
    """)

    journal_dict = load_pubmed_journal_abbreviations()
    full_to_abbrev = {v: k for k, v in journal_dict.items()}

    # Quick fix: Add missing journals
    missing_journals = ["The Lancet", "BMJ"]
    for journal in missing_journals:
        if journal not in full_to_abbrev:
            full_to_abbrev[journal] = journal

    journal_options = list(full_to_abbrev.keys())
    journal_options.sort()

    email = st.text_input("ğŸ“§ Enter your email (Optional):", help="Used for NCBI API compliance.")
    
    # Journal selection
    selected_journals = st.multiselect("ğŸ“˜ Select journal(s) (Optional):", options=journal_options)

    # Include preprints checkbox moved here
    include_preprints = st.checkbox("ğŸ“‘ Include preprints", help="Currently supports bioRxiv and medRxiv.")

    date_option = st.selectbox("ğŸ“… Select date range:", ["Past Week", "Past Month", "Past Year", "Custom"])
    today = datetime.today().date()

    if date_option == "Custom":
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.text_input("Start date (YYYY-MM or YYYY-MM-DD):")
        with col2:
            end_date = st.text_input("End date (YYYY-MM or YYYY-MM-DD):")
    else:
        days = {"Past Week": 7, "Past Month": 30, "Past Year": 365}[date_option]
        start_date = str(today - timedelta(days=days))
        end_date = str(today)

    raw_keywords = st.text_area("â“ Enter your search keyword (Optional):", height=100,
        help="""ğŸ” **Search Tips**  
        - Use **AND**, **OR**, **NOT**  
        - Wrap phrases in **parentheses**: *(cadmium exposure)*  
        - Wildcards: `metagenom*`, `wom?n`
        """)

    # Manual Search Button with Rate Limiting
    if st.button("ğŸ” Search"):
        # Rate limiting check first
        if not rate_limiter.can_make_request():
            st.stop()  # This stops execution if rate limited

        try:
            # Modified validation - allow search if either journals are selected OR preprints are included
            if not selected_journals and not include_preprints:
                st.error("âŒ Please select at least one journal or include preprints.")
                st.stop()

            # Only process journal validation if journals are selected
            # Process selected journals
            if selected_journals:
                formatted_journals = validate_and_format_journals(selected_journals)
                if formatted_journals is None:  # Validation failed
                    st.stop()
            else:
                formatted_journals = []

            # Validation
            if not formatted_journals and not include_preprints:
                st.error("âŒ Please select at least one journal or enable preprints.")
                st.stop()

            # Validate keywords early if provided
            if raw_keywords.strip():
                if raw_keywords.count("(") != raw_keywords.count(")"):
                    st.warning("âš ï¸ Unbalanced parentheses.")
                    st.stop()
                user_keywords = raw_keywords.strip()
                compiled_filter = compile_keyword_filter(raw_keywords)
                pubmed_keywords = format_boolean_keywords_for_pubmed(raw_keywords)
                keywords = pubmed_keywords
            else:
                keywords = None

            # Create placeholders for status updates
            status_placeholder = st.empty()
            progress_bar = st.progress(0)
            
            # Initialize search
            status_placeholder.info("ğŸš€ Starting search...")
            progress_bar.progress(10)
            
            all_articles = []
            total_journals = len(selected_journals) if selected_journals else 0
            preprint_servers = ["biorxiv", "medrxiv"] if include_preprints else []
            total_sources = total_journals + len(preprint_servers)
            
            current_step = 0
            
            # Search PubMed journals (only if journals are selected) - WITH RATE LIMITING
            if selected_journals:
                for i, journal in enumerate(selected_journals):
                    current_step += 1
                    status_placeholder.info(f"ğŸ” Searching {journal}... ({current_step}/{total_sources})")
                    progress_bar.progress(int((current_step / total_sources) * 80))
                    
                    try:
                        # Use the safe search method from rate limiter
                        query = build_pubmed_query(journal, start_date, end_date, keywords)
                        search_results = rate_limiter.safe_pubmed_search(query, max_results=100)
                        
                        if search_results and search_results.get("IdList"):
                            # Use safe fetch method for getting article details
                            articles_xml = rate_limiter.safe_pubmed_fetch(search_results["IdList"])
                            
                            if articles_xml:
                                # Your existing article processing logic
                                # You'll need to adapt this part to work with the XML data
                                # For now, let's use your existing function but add rate limiting
                                articles = fetch_pubmed_articles_by_date(journal, start_date, end_date, keywords, rate_limiter)

                                for article in articles:
                                    article["Journal"] = journal
                                all_articles.extend(articles)
                                
                                # Show intermediate results
                                if articles:
                                    status_placeholder.success(f"âœ… Found {len(articles)} articles in {journal}")
                                else:
                                    status_placeholder.info(f"ğŸ“­ No articles found in {journal}")
                            else:
                                status_placeholder.warning(f"âš ï¸ Failed to fetch details for {journal}")
                        else:
                            status_placeholder.info(f"ğŸ“­ No articles found in {journal}")
                                
                    except Exception as e:
                        st.error(f"âŒ Error searching {journal}: {str(e)}")
                        continue

            # Search preprints if requested (no rate limiting needed for preprints)
            if include_preprints:
                for server in preprint_servers:
                    current_step += 1
                    status_placeholder.info(f"ğŸ” Searching {server} preprints... ({current_step}/{total_sources})")
                    progress_bar.progress(int((current_step / total_sources) * 80))
                    
                    try:
                        preprints = fetch_preprints(
                            server=server,
                            start_date=start_date,
                            end_date=end_date,
                            keywords=raw_keywords
                        )
                        for article in preprints:
                            article["Journal"] = server
                            article["Source"] = "Preprint"
                        all_articles.extend(preprints)
                        
                        # Show intermediate results
                        if preprints:
                            status_placeholder.success(f"âœ… Found {len(preprints)} preprints in {server}")
                        else:
                            status_placeholder.info(f"ğŸ“­ No preprints found in {server}")
                            
                    except Exception as e:
                        st.error(f"âŒ Error searching {server}: {str(e)}")
                        continue

            # Rest of your existing code remains the same...
            # Finalize results
            progress_bar.progress(90)
            status_placeholder.info("ğŸ“Š Processing results...")

            if all_articles:
                # Add Source field for PubMed articles
                for article in all_articles:
                    if "Source" not in article:
                        article["Source"] = "PubMed"

                # Standardize date formats before processing
                all_articles = standardize_date_format(all_articles)
                all_articles = standardize_doi_format(all_articles)
                
                merged = merge_and_highlight_articles(all_articles, [], raw_keywords)
                df = pd.DataFrame(merged)
                
                progress_bar.progress(100)
                status_placeholder.success(f"ğŸ‰ Search completed! Found {len(df)} articles total.")
                
                # Display results
                with st.expander("ğŸ“Š Search Summary & Results", expanded=True):
                    # Search parameters in a compact format
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**ğŸ“˜ Journals:** {', '.join(selected_journals[:2]) + ('...' if len(selected_journals) > 2 else '') if selected_journals else 'None'}")
                        st.write(f"**ğŸ“… Date Range:** {start_date} to {end_date}")
                    with col2:
                        st.write(f"**ğŸ”‘ Keywords:** {raw_keywords[:30] + '...' if len(raw_keywords) > 30 else raw_keywords if raw_keywords else 'None'}")
                        st.write(f"**ğŸ“‘ Preprints:** {'Yes' if include_preprints else 'No'}")
                    
                    # Results breakdown
                    st.write("---")
                    st.write("**ğŸ“ˆ Results by Source:**")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        if "Source" in df.columns:
                            source_counts = df["Source"].value_counts()
                            for source, count in source_counts.items():
                                st.write(f"â€¢ **{source}:** {count} articles")
                    
                    with col2:
                        if "Journal" in df.columns:
                            journal_counts = df["Journal"].value_counts()
                            st.write("**By Journal/Platform:**")
                            for journal, count in journal_counts.head(5).items():  # Show top 5
                                st.write(f"â€¢ {journal}: {count}")
                            if len(journal_counts) > 5:
                                st.write(f"â€¢ ... and {len(journal_counts) - 5} more")
                    
                    # Show PubMed query if applicable
                    if keywords and selected_journals:
                        with st.expander("ğŸ” Technical Details", expanded=False):
                            query_preview = build_pubmed_query(
                                journal=selected_journals[0],
                                start_date=start_date,
                                end_date=end_date,
                                keywords=keywords
                            )
                            st.caption("ğŸ”§ Actual PubMed API query used for search:")
                            st.code(query_preview, language="none")
                
                # Show sample results first
                with st.expander("ğŸ‘€ Preview Results", expanded=False):
                    st.dataframe(df.head(10))
                
                # Download button moved below preview
                csv_data = df.to_csv(index=False).encode("utf-8")
                st.download_button(
                    label="ğŸ“¥ Download Results as CSV",
                    data=csv_data,
                    file_name=f"JournalTracker_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )

                # if not df.empty:
                #     # Show summary
                #     st.markdown(f"### ğŸ“Š Search Results ({len(df)} articles)")
                    
                #     # Display the DataFrame
                #     st.dataframe(df, use_container_width=True)
                    
                #     # Add download button
                #     csv_buffer = io.BytesIO()
                #     csv_content = df.to_csv(index=False)
                #     csv_buffer.write(csv_content.encode())
                #     csv_buffer.seek(0)
                    
                #     st.download_button(
                #         label="ğŸ“¥ Download Results as CSV",
                #         data=csv_buffer.getvalue(),
                #         file_name=f"journal_tracker_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                #         mime="text/csv",
                #         help="Download your search results as a CSV file"
                #     )
                    
                #     # Optional: Show first few results as preview
                #     if len(df) > 0:
                #         st.markdown("### ğŸ“‹ Preview (First 3 Results)")
                #         preview_df = df.head(3)
                #         for idx, row in preview_df.iterrows():
                #             with st.expander(f"ğŸ“„ {row.get('Title', 'No Title')}", expanded=False):
                #                 st.write(f"**Journal:** {row.get('Journal', 'N/A')}")
                #                 st.write(f"**Publication Date:** {row.get('Publication Date', 'N/A')}")
                #                 st.write(f"**Abstract:** {row.get('Abstract', 'N/A')[:300]}...")
                #                 if row.get('DOI', 'N/A') != 'N/A':
                #                     st.write(f"**DOI:** {row.get('DOI', 'N/A')}")
                # else:
                #     # This section should already be working from your existing code
                #     progress_bar.progress(100)
                #     status_placeholder.warning("ğŸ“­ No articles found matching your criteria.")
                    
                #     # Show suggestions
                #     st.info("""
                #     **No results found. Try:**
                #     - Expanding your date range
                #     - Using broader keywords
                #     - Checking different journals
                #     - Including preprints
                #     """)
                
            else:
                progress_bar.progress(100)
                status_placeholder.warning("ğŸ“­ No articles found matching your criteria.")
                
                # Show suggestions
                st.info("""
                **No results found. Try:**
                - Expanding your date range
                - Using broader keywords
                - Checking different journals
                - Including preprints
                """)

        except Exception as e:
            st.error(f"âŒ Unexpected error: {e}")
            # Clear progress indicators on error
            if 'status_placeholder' in locals():
                status_placeholder.empty()
            if 'progress_bar' in locals():
                progress_bar.empty()


    # --- Subscribe toggle ---
    subscribe = st.checkbox("ğŸ“¬ Subscribe to automatic updates", key="subscribe_toggle")

    # Subscription section only renders when checked
    if subscribe:
        col1, col2 = st.columns(2)
        with col1:
            freq_choice = st.selectbox("ğŸ” Update Frequency", ["weekly", "monthly", "custom"])
        with col2:
            subscriber_email = st.text_input("ğŸ“§ Email to receive updates")

        if freq_choice == "custom":
            custom_days = st.number_input("ğŸ”§ Custom interval (days):", min_value=1, step=1)
            frequency = f"every {custom_days} days"
        else:
            frequency = freq_choice

        st.markdown("âœ… Confirm your subscription")

        # source summary
        sources_summary = []
        if selected_journals:
            sources_summary.append(f"Journals: {', '.join(selected_journals)}")
        if include_preprints:
            sources_summary.append("Preprints: bioRxiv, medRxiv")

        sources_text = " | ".join(sources_summary) if sources_summary else "None selected"

        st.info(f"""
                **Email**: {subscriber_email or "Not provided"}  
                **Sources**: {sources_text}
                **Keywords**: {raw_keywords if raw_keywords else "None"}  
                **Frequency**: {frequency}
                """)

        if st.button("ğŸ“© Confirm and Subscribe"):
            if not subscriber_email:
                st.error("âŒ Please provide an email address.")
            elif not selected_journals and not include_preprints:
                st.error("âŒ Please select at least one journal or include preprints.")
            else:
                formatted_journals = [full_to_abbrev.get(name) for name in selected_journals if full_to_abbrev.get(name)] if selected_journals else []
                
                # Execute search immediately for subscription
                if 'df' in locals() and not df.empty:
                    # User just performed a search - use those results
                    csv_bytes = df.to_csv(index=False).encode("utf-8")
                    has_results = True
                else:
                    # User is subscribing without searching - execute search now
                    search_results = execute_subscription_search(
                        journals=formatted_journals,
                        keywords=raw_keywords,
                        include_preprints=include_preprints,
                        frequency=frequency
                    )
                    if search_results is not None and not search_results.empty:
                        csv_bytes = search_results.to_csv(index=False).encode("utf-8")
                        has_results = True
                    else:
                        csv_bytes = None
                        has_results = False

                # Store subscription first

                result = store_user_subscription(
                    email=subscriber_email,
                    journals=formatted_journals,
                    keywords=raw_keywords,
                    # start_date=start_date, # might now need these two parameters for now
                    # end_date=end_date,
                    frequency=frequency,
                    include_preprints=include_preprints
                )

                if result["status"] == "success":

                    subscription_data = result["data"]  # Get the subscription data
                    subscription_id = subscription_data["id"]  # Extract the ID

                    # Generate proper unsubscribe token
                    unsubscribe_token = generate_unsubscribe_token(subscription_id)
                    
                    # Add debugging
                    st.write(f"ğŸ”§ Debug - Generated token (first 20 chars): {unsubscribe_token[:20] if unsubscribe_token else 'None'}...")    

                    if unsubscribe_token:
                        unsubscribe_link = f"{BASE_URL}?token={unsubscribe_token}"
                    else:
                        st.error("âŒ Failed to generate unsubscribe token")
                        st.stop()

                    # Build source description
                    source_list = []
                    if formatted_journals:
                        source_list.extend(formatted_journals)
                    if include_preprints:
                        source_list.extend(['bioRxiv', 'medRxiv'])
                    source_description = ', '.join(source_list) if source_list else 'No sources selected'

                    if has_results and csv_bytes is not None:
                        # Generate download token for results
                        download_token = generate_download_token(
                            csv_bytes, 
                            subscriber_email, 
                            subscription_id=subscription_id  # Pass the subscription ID
                        )
                        
                        if download_token:
                            download_link = f"{BASE_URL}?token={download_token}&action=download"
                            # ... rest of your email code
                        else:
                            st.error("âŒ Failed to generate download link")
                            st.stop()

                        # Calculate result count
                        result_count = len(pd.read_csv(io.StringIO(csv_bytes.decode('utf-8'))))
                        
                        email_body = f"""Hi {subscriber_email},

                You have successfully subscribed to automatic PubMed updates.

                ğŸ“Š SUBSCRIPTION DETAILS:
                ğŸ“˜ Journals: {', '.join(formatted_journals) if formatted_journals else 'None'}
                ğŸ“‘ Preprints: {('bioRxiv, medRxiv' if include_preprints else 'None')}
                ğŸ” All Sources: {source_description}
                ğŸ”‘ Keywords: {raw_keywords or 'None'}
                ğŸ” Frequency: {frequency}

                ğŸ“¥ YOUR CURRENT RESULTS ({result_count} articles found):
                Your search results are available for download (expires in 24 hours):
                ğŸ”— {download_link}

                You will receive your next update in {get_next_update_timeframe(frequency)}.

                ğŸ”“ UNSUBSCRIBE:
                {unsubscribe_link}

                â€“ PubMed Tracker Team
                        """
                        
                        email_subject = f"ğŸ“¬ Journal Tracker: Subscription Confirmed ({result_count} results)"
                        success_message = f"âœ… Subscription confirmed! {result_count} results sent to {subscriber_email}"
                    else:
                        # No results found
                        email_body = f"""Hi {subscriber_email},

                You have successfully subscribed to automatic PubMed updates.

                ğŸ“Š SUBSCRIPTION DETAILS:
                ğŸ“˜ Journals: {', '.join(formatted_journals) if formatted_journals else 'None'}
                ğŸ“‘ Preprints: {('bioRxiv, medRxiv' if include_preprints else 'None')}
                ğŸ” All Sources: {source_description}
                ğŸ”‘ Keywords: {raw_keywords or 'None'}
                ğŸ” Frequency: {frequency}

                ğŸ“­ CURRENT SEARCH STATUS:
                No articles found matching your criteria for the selected time period.

                You will receive your next update in {get_next_update_timeframe(frequency)} (only if results are found).

                ğŸ”“ UNSUBSCRIBE:
                {unsubscribe_link}

                â€“ PubMed Tracker Team
                        """
                        
                        email_subject = "ğŸ“¬ Journal Tracker: Subscription Confirmed (No results)"
                        success_message = f"âœ… Subscription confirmed! Confirmation email sent to {subscriber_email}"
                    
                    try:
                        # âœ… UPDATED: Pass email configuration explicitly
                        send_email(
                            to_email=subscriber_email,
                            subject=email_subject,
                            body=email_body,
                            sender_email=BREVO_SENDER_EMAIL,
                            sender_name=BREVO_SENDER_NAME,
                            api_key=BREVO_API_KEY
                        )
                        st.success(success_message)
                    except Exception as e:
                        st.error(f"âŒ Subscription failed: {e}")
                
                elif result["status"] == "error":
                    st.error(f"âŒ {result['message']}")
                    if "Maximum of 3" in result["message"]:
                        st.info("ğŸ’¡ **Tip:** You can manage your existing subscriptions by using the unsubscribe link in any of your previous emails.")
                                
                else:
                    st.error(f"âŒ Subscription failed: {result.get('message', 'Unknown error')}")

# Add Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: #666; font-size: 0.8em; padding: 20px 0;'>
        Please report issues to <a href='https://github.com/rzhan186/Journal_tracker/issues' target='_blank'>GitHub</a>
    </div>
    """, 
    unsafe_allow_html=True
)
